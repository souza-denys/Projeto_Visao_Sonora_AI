{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souza-denys/Projeto_Visao_Sonora_AI/blob/main/Imers%C3%A3o_Intelig%C3%AAncia_Artificial_2%C2%AA_Edi%C3%A7%C3%A3o_Projeto_Vis%C3%A3o_Sonora_AI_para_Pessoas_com_Defici%C3%AAncia_Visual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto: Visão Sonora AI para Pessoas com Deficiência Visual\n",
        "Introdução:\n",
        "\n",
        "A barreira da deficiência visual limita a percepção do mundo, dificultando tarefas simples do dia a dia. A tecnologia surge como um farol de esperança, abrindo portas para a inclusão e autonomia. Este projeto propõe o desenvolvimento de um aplicativo Vizu inovador que utiliza inteligência artificial (IA) para auxiliar pessoas com deficiência visual a lerem imagens em tempo real.\n",
        "\n",
        "**Funcionalidades:**\n",
        "\n",
        "Leitura de Imagens em Tempo Real: O aplicativo utilizará técnicas de IA, como reconhecimento de objetos para interpretar o conteúdo de imagens capturadas.\n",
        "\n",
        "Descrição em Áudio Detalhada: A IA fornecerá uma descrição da imagem, incluindo objetos, cores, texturas e até mesmo texto presente em documentos.\n",
        "\n",
        "Interação Intuitiva: A interface do aplicativo será acessível, permitindo que usuários naveguem facilmente com comandos de voz."
      ],
      "metadata": {
        "id": "BGCTtPqpUrxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requisitos:**\n",
        "\n",
        "Este projeto utiliza a API do Google Gemini conectada ao Google Colab para descrever imagens em tempo real durante chamadas de vídeo, auxiliando pessoas com deficiência visual."
      ],
      "metadata": {
        "id": "9vhiI0ysVNwa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GCNUlkXFT84",
        "outputId": "387cc405-19ea-4c2a-cd7a-0df9096ed909",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.1\n"
          ]
        }
      ],
      "source": [
        "# Instalar bibliotecas.\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas.\n",
        "import google.generativeai as genai\n",
        "from gtts import gTTS\n",
        "from google.colab import userdata\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import google.ai.generativelanguage as glm\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "A_G47mVTN3fd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar a API_KEY e o modelo.\n",
        "API_KEY = userdata.get('SECRET_KEY')\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.0-pro-latest')"
      ],
      "metadata": {
        "id": "IkfogKeYCH9W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blob(path):\n",
        "  pil_image = Image.open(path)\n",
        "\n",
        "  img_byte_arr = BytesIO()\n",
        "\n",
        "  pil_image.save(img_byte_arr, format='JPEG')\n",
        "\n",
        "  return glm.Blob(\n",
        "    mime_type='image/jpeg',\n",
        "    data=img_byte_arr.getvalue()\n",
        "  )"
      ],
      "metadata": {
        "id": "vHObUTJWNCbj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sintetizar_audio(texto):\n",
        "    \"\"\"Sintetiza o texto em áudio.\n",
        "\n",
        "    Args:\n",
        "        texto (str): Texto a ser sintetizado.\n",
        "    \"\"\"\n",
        "\n",
        "    # Language in which you want to convert\n",
        "    language = 'pt'\n",
        "\n",
        "    # Passing the text and language to the engine,\n",
        "    # here we have marked slow=False. Which tells\n",
        "    # the module that the converted audio should\n",
        "    # have a high speed\n",
        "    myobj = gTTS(text=texto, lang=language, slow=False)\n",
        "\n",
        "    # Saving the converted audio in a mp3 file named\n",
        "    # welcome\n",
        "    myobj.save(\"audio.mp3\")"
      ],
      "metadata": {
        "id": "C3aF8W0nw2J6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot.\n",
        "convo = model.start_chat(history=[])\n",
        "\n",
        "image_path = input(\"Qual a imagem que deseja usar? \")\n",
        "\n",
        "image_blob = get_blob(image_path)\n",
        "\n",
        "image_text = convo.send_message([\"Descreva a imagem a seguir: \", image_blob], stream=True)\n",
        "\n",
        "audio_path = sintetizar_audio(image_text)\n",
        "\n",
        "os.system(f\"start {audio_path}\")"
      ],
      "metadata": {
        "id": "oebRjExvKSwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Considerações:\n",
        "Este projeto é um exemplo básico e pode ser expandido com funcionalidades adicionais, como comandos de voz para controlar o aplicativo. A qualidade da descrição gerada pelo Google Gemini depende da qualidade da imagem capturada. É importante garantir a acessibilidade do aplicativo, utilizando bibliotecas e práticas recomendadas para desenvolvimento acessível."
      ],
      "metadata": {
        "id": "5dJW3XWeU8qe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}